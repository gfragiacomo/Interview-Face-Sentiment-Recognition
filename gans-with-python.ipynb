{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7NDjY-bckXZ"
      },
      "source": [
        "# GANs with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av08z65lckXg"
      },
      "source": [
        "## Importing Libraries\n",
        "\n",
        "Like in the previous workshop, we're going to import some libraries for the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-DxwK3pckXi",
        "outputId": "51fb8bc5-8153-498d-f0e3-6672717b6763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability) (3.1.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability) (0.1.9)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability) (25.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow tensorflow-probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ggJNE19puADT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code has been added to specify the GPU"
      ],
      "metadata": {
        "id": "l9jfDjiYJxEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"TensorFlow is using the GPU\")\n",
        "else:\n",
        "  print(\"Tensorflow is using the CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thIuc3NpJDZr",
        "outputId": "420d1eb5-5655-4941-8c40-7b073bd54f64"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "TensorFlow is using the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taXp20OmckXj"
      },
      "source": [
        "## A quick intro to booleans\n",
        "\n",
        "### Data type recap\n",
        "\n",
        "Earlier we discussed different types of variables you see in your code. The main examples we went through were strings (text data), integers (whole-numbers), and floats (numbers with a decimal place).\n",
        "\n",
        "A quick recap:\n",
        "```python\n",
        "my_string = \"some text!\"\n",
        "my_float = 39.59382\n",
        "my_int = 20\n",
        "```\n",
        "### Bools and why we're using them\n",
        "\n",
        "There is another basic data type that we frequently use in Python called booleans (or bools). These can either have the values `True` or `False`. They are used when we want a part of our code to run only when a certain condition has been met.\n",
        "\n",
        "The code we are using can take several hours to complete (depending on how many images you give and some other factors), so it's been written in such a way that it is possible to save the progress that the code has made so that it can pick up from where it left off later. THis is also useful if the code crashes for whatever reason, as the progress it has made will be preserved.\n",
        "\n",
        "However, this has the downside of creating progress files in your Google Drive folder that can build up in size quite quickly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhzubzvPckXk"
      },
      "source": [
        "### Bools for our GAN\n",
        "\n",
        "Before running the code, we will set values for the following bools:\n",
        "- `do_preprocess` - Determines if we run or skip the code for resizing our image files. This will need to be done at least once.\n",
        "- `from_checkpoint` - Determines if the GAN starts from scratch, or picks up where it left off by loading a model file. For the first run this will have to be set to False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GAwmJcujckXl"
      },
      "outputs": [],
      "source": [
        "do_preprocess = True\n",
        "from_checkpoint = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brchl4lmckXm"
      },
      "source": [
        "Here is a basic example of what bools allow you to do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC08FinIckXn",
        "outputId": "29016280-0f58-47a8-c769-5fd105dfa2bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We will see this printed.\n",
            "This will also be printed\n"
          ]
        }
      ],
      "source": [
        "my_bool = True\n",
        "\n",
        "if my_bool:\n",
        "    print(\"We will see this printed.\")\n",
        "\n",
        "if my_bool:\n",
        "    print(\"This will also be printed\")\n",
        "else:\n",
        "    print(\"But not this.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S5n5LbfckXo"
      },
      "source": [
        "This code contains an `if` statement. This is another keyword in Python used for conditional execution, basically meaning it helps us write code that is only run some of the time. Here we have used it to ensure that some text is printed only when `my_bool` is True.\n",
        "\n",
        "Now let's see what happens when something is false.\n",
        "\n",
        "**Exercise**: What will the output be?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOwTGv79ckXo"
      },
      "outputs": [],
      "source": [
        "my_bool = False\n",
        "\n",
        "if my_bool:\n",
        "    print(\"This will be printed. Or will it...?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRHjoKjLckXp"
      },
      "source": [
        "You may remember that the first workshop showed us how to use `type()` to find the type of some data. Now we can use it with a bool to see that it is in fact a bool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt5lRhDMckXp"
      },
      "outputs": [],
      "source": [
        "print(type(True), type(False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MvvB5M3ckXq"
      },
      "source": [
        "### Downloading Some Data\n",
        "\n",
        "Now that we understand a bit about what booleans do, please set the bool below to True or False depending on whether you've uploaded 500+ image files to Google Drive and have put them in the right folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uHf6TJ9t_f-c"
      },
      "outputs": [],
      "source": [
        "student_uploaded_own_data = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJxzxpiXckXq"
      },
      "source": [
        "## Check the GPU\n",
        "\n",
        "The Tensorflow library allows us to perform calculations with a GPU or CPU. Setting a GPU up on a desktop machine can be tricky, and sometimes a library won't recognise your GPU as being on your system, even when one is present. For this reason Tensorflow and other Python libraries that utilise the GPU often have a command for checking that a GPU has been detected on the system. This lets you know if you can continue coding, or if you need to do some troubleshooting and figure out why things didn't install properly.\n",
        "\n",
        "Fortunately we don't need to worry about these things when using Colab. The GPU is already setup for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGm8QAAeqPNi",
        "outputId": "7c1a7566-1a5e-4d3a-efc7-3723d73bbae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpvz-BbbckXs"
      },
      "source": [
        "Google Colab is somtimes able to tell that a Python Notebook requies the GPU, so you should have automatically been given a T4 runtime. You can check this in the top right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FhySpKmckXt"
      },
      "source": [
        "## Prepare the Folder Names (and Data?)\n",
        "\n",
        "This code will create quite a bit of output, and so we'll need to create some folders to save all these files:\n",
        "\n",
        "- One folder for the resized images that we will feed into the GAN\n",
        "- Another folder for the model files that act as snapshots of how far the GAN has come along\n",
        "- And another for the computer-generated images\n",
        "\n",
        "Like in the previous workshop, the `os` library will be used for creating our paths. This for safety, as `os` knows what to do regardless of if you are running Windows, Linux, or Mac."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu4RylccckXt",
        "outputId": "c0038a0d-2719-42ef-9123-b283ed065fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "project_dir = \"./drive/MyDrive/\"\n",
        "GANS_WORKSHOP_FOLDER = \"gans-workshop-files\"\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    project_dir = os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NImrmxwzckXt"
      },
      "source": [
        "### A bit about `try-except`\n",
        "\n",
        "The purpose of `try-except` is to give the code a kind of Plan B on what to do when a certain block of code creates an error. Sometimes we are _expecting_ an error in a particular situation, and know what we want the code to do should this happen. This is where a `try-except` block comes into play. It allows us to say \"If you run across this problem as the code runs, do this instead.\"\n",
        "\n",
        "Here I am mounting the Google Drive folder in a `try-except` block because sometimes I run this code on a desktop. In this scenario the `from google.colab import drive` would lead to a `ModuleNotFoundError`. This is an error you get when you try to import a library that hasn't been installed on your system. When I am running this code on a desktop machine I am not importing Colab and instead getting the input files from my hard drive, and so I tell the code to use `os.getcwd()` as the path to work from. This is the _current working directory_.\n",
        "\n",
        "Here's an example below of _catching_ an error caused by using the wrong index for a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li4iD1IbckXt"
      },
      "outputs": [],
      "source": [
        "# This list contains three items\n",
        "my_list = [1, 2, 3]\n",
        "\n",
        "# This is how we print the items in a list line by line\n",
        "print(my_list[0])\n",
        "print(my_list[1])\n",
        "print(my_list[2])\n",
        "\n",
        "try:\n",
        "    # I am going to try and print the 4th item in the list\n",
        "    print(my_list[3])\n",
        "    print(\"Will the code reach this point?\")\n",
        "except IndexError:\n",
        "    print(\"You have accessed something outside of the list.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VycDXyntckXt"
      },
      "source": [
        "## Downloading the Files\n",
        "\n",
        "Now with that out of the way we can start sorting out the images to give to the GAN. Pick a type of image you want to download if you didn't already prepare some data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mnURcOuLckXu"
      },
      "outputs": [],
      "source": [
        "# @title Choose the type of data you wish to download if you don't already have something { display-mode: \"form\" }\n",
        "\n",
        "data_folder_name = \"abstract-paintings\"  # @param [\"cats\", \"flowers\", \"abstract-paintings\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jdyt3mqckXu"
      },
      "source": [
        "Now a conditional statement will download some data if it's needed, otherwise we'll go with the data you already have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "exSovTIzckXu"
      },
      "outputs": [],
      "source": [
        "GANS_WORKSHOP_FOLDER = \"gans-workshop-files\"\n",
        "\n",
        "if student_uploaded_own_data:\n",
        "    # Change this to the name of your data folder\n",
        "    data_folder_name = \"pokemon\"\n",
        "else:\n",
        "    from urllib import request  # This is for downloading\n",
        "    import zipfile  # This is for handling zip files\n",
        "\n",
        "    data_path = os.path.join(project_dir, GANS_WORKSHOP_FOLDER, data_folder_name)\n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path, exist_ok=True)\n",
        "        print(f\"Downloading {data_folder_name} dataset...\")\n",
        "        local_filename, _ = request.urlretrieve(\n",
        "            f\"https://github.com/DolicaAkelloEgwel/gans-datasets/raw/master/{data_folder_name}.zip\"\n",
        "        )\n",
        "        with zipfile.ZipFile(local_filename, \"r\") as downloaded_dataset:\n",
        "            downloaded_dataset.extractall(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGj0s8qFckXu"
      },
      "source": [
        "We're going to need quite a few folders for all the files that will be created from the code. These will be\n",
        "- A folder for our resized data\n",
        "- A folder for our model/checkpoint files\n",
        "- A folder for the GANs output images\n",
        "\n",
        "For the time being, we're just going to set the paths for these folders. That's because these folders may already exist, so there will need to be some conditional logic used to check if these folders even need to be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TrexhUYsckXv"
      },
      "outputs": [],
      "source": [
        "workshop_dir = os.path.join(project_dir, GANS_WORKSHOP_FOLDER)\n",
        "data_dir = os.path.join(workshop_dir, data_folder_name)\n",
        "data_resized_dir = os.path.join(workshop_dir, f\"{data_folder_name}-resized\")\n",
        "models_folder = os.path.join(workshop_dir, f\"{data_folder_name}-models\")\n",
        "image_folder = os.path.join(workshop_dir, f\"{data_folder_name}-gans-images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H8ody46ckXv"
      },
      "source": [
        "## Preprocess the Files\n",
        "\n",
        "This code is designed to work with 128x128 images, so we're going to resize the images and place them in a new folder. Again, `os.mkdir` is used for this.\n",
        "\n",
        "With the folder for our preprocessed files created, we can now resize the images and save them there. In order to do this we loop through all the images in our data directory using `os.listdir`. This is something that will list all the files it can find in a folder, which is why I am using `image_filename` as the placeholder.\n",
        "\n",
        "Our `image_filename` is then sent to the `cv2.imread` command which will load the file into an array, and then sent again to the `cv2.resize` command so that it may be resized. Finally the resized images are saved to our `data_resized_dir` using the `cv2.imwrite` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "q9kJecu8ckXv"
      },
      "outputs": [],
      "source": [
        "def crop_image_in_centre(image: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Crops an image in the centre to make it square.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): The image data to reshape.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The cropped image.\n",
        "    \"\"\"\n",
        "    height, width = image.shape[:2]\n",
        "    # Only do the cropping if the image isn't square\n",
        "    if height != width:\n",
        "        min_side = min(height, width)\n",
        "        top, bot = (height - min_side) // 2, height - (height - min_side) // 2\n",
        "        left, right = (width - min_side) // 2, width - (width - min_side) // 2\n",
        "        image = image[top:bot, left:right, :]\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KjF7ms0ckXv"
      },
      "source": [
        "### Loading the Image Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mIQnG0tqP8y"
      },
      "outputs": [],
      "source": [
        "if do_preprocess:\n",
        "    # Make a folder for the resized images if one doesn't already exist\n",
        "    if not os.path.isdir(data_resized_dir):\n",
        "        os.mkdir(data_resized_dir)\n",
        "\n",
        "    # Go through each of our input images, resize them, and then save them to the new folder\n",
        "    for image_filename in os.listdir(data_dir):\n",
        "        try:\n",
        "            image = cv2.imread(os.path.join(data_dir, image_filename))\n",
        "            image = crop_image_in_centre(image)\n",
        "            image = cv2.resize(image, (128, 128))\n",
        "            cv2.imwrite(os.path.join(data_resized_dir, image_filename), image)\n",
        "        except Exception as e:\n",
        "            print(str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJCylyXockXw"
      },
      "source": [
        "Sometimes stray files such as `.DS_Store` make their way into our folders. Our `os.listdir` loop is simply going to find all the files in a folder and isn't smart enough to know that not all of these files will be images. This is why we use a `try-except` again to allow the code to keep going even when `cv2.imread` fails. This is fine, because if it fails to read a file as an image then the file most likely wasn't an actual image, so we can just ignore it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlcU4OtgckXw"
      },
      "source": [
        "## Setup Helper Functions\n",
        "\n",
        "These are some simple functions for getting image data. This helps with keeping the code modular."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQGHb9DPqeBY"
      },
      "outputs": [],
      "source": [
        "def get_image(image_path: str, mode: str) -> np.ndarray:\n",
        "    \"\"\"Loads a numpy image.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): The path for the image to load.\n",
        "        mode (str): The mode to give when converting the image.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The image in the form of a numpy array.\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(image_path).convert(mode))\n",
        "\n",
        "\n",
        "def get_batch(image_files: list[str], mode: str) -> np.ndarray:\n",
        "    \"\"\"Creates a batch of images.\n",
        "\n",
        "    Args:\n",
        "        image_files (list): A list of several image files.\n",
        "        mode (str): The most to use when converting the images.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: An array of a batch of images.\n",
        "    \"\"\"\n",
        "    data_batch = np.array(\n",
        "        [get_image(sample_file, mode) for sample_file in image_files]\n",
        "    ).astype(np.float32)\n",
        "\n",
        "    # Make sure the images are in 4 dimensions\n",
        "    if len(data_batch.shape) < 4:\n",
        "        data_batch = data_batch.reshape(data_batch.shape + (1,))\n",
        "\n",
        "    return data_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViLJktfbckXw"
      },
      "source": [
        "This will create a function that will plot several images in a grid. We'll use this to monitor the progress of the GAN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpNvZp97rZwB"
      },
      "outputs": [],
      "source": [
        "def images_square_grid(images: np.ndarray, mode: str) -> Image:\n",
        "    \"\"\"Plots three images in a grid.\n",
        "\n",
        "    Args:\n",
        "        images (np.ndarray): A batch of 9 images.\n",
        "        mode (str): The mode in which the images will be displayed.\n",
        "\n",
        "    Returns:\n",
        "        PIL.Image: An Image object containing the 9 pictures.\n",
        "    \"\"\"\n",
        "    # Get maximum size for square grid of images\n",
        "    save_size = math.floor(np.sqrt(images.shape[0]))\n",
        "\n",
        "    # Scale to 0-255\n",
        "    images = (((images - images.min()) * 255) / (images.max() - images.min())).astype(\n",
        "        np.uint8\n",
        "    )\n",
        "\n",
        "    # Put images in a square arrangement\n",
        "    images_in_square = np.reshape(\n",
        "        images[: save_size * save_size],\n",
        "        (save_size, save_size, images.shape[1], images.shape[2], images.shape[3]),\n",
        "    )\n",
        "    if mode == \"L\":\n",
        "        images_in_square = np.squeeze(images_in_square, 4)\n",
        "\n",
        "    # Combine images to grid image\n",
        "    new_im = Image.new(mode, (images.shape[1] * save_size, images.shape[2] * save_size))\n",
        "    for col_i, col_images in enumerate(images_in_square):\n",
        "        for image_i, image in enumerate(col_images):\n",
        "            im = Image.fromarray(image, mode)\n",
        "            new_im.paste(im, (col_i * images.shape[1], image_i * images.shape[2]))\n",
        "\n",
        "    return new_im"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6PaI85GckXx"
      },
      "source": [
        "This creates a `Dataset` object for Tensorflow to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcnHs0cbckXx"
      },
      "outputs": [],
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, data_files: list[str]):\n",
        "        \"\"\"Initialised the Dataset object\n",
        "\n",
        "        Args:\n",
        "            data_files (np.ndarray): An array of pictures.\n",
        "        \"\"\"\n",
        "        IMAGE_WIDTH = 128\n",
        "        IMAGE_HEIGHT = 128\n",
        "\n",
        "        self.image_mode = \"RGB\"\n",
        "        image_channels = 3\n",
        "\n",
        "        self.data_files = data_files\n",
        "        self.shape = len(data_files), IMAGE_WIDTH, IMAGE_HEIGHT, image_channels\n",
        "\n",
        "    def get_batches(self, batch_size: int) -> np.ndarray:\n",
        "        \"\"\"Gets a batch of images.\n",
        "\n",
        "        Args:\n",
        "            batch_size (int): The number of images that should be in the batch.\n",
        "\n",
        "        Yields:\n",
        "            np.ndarray: A batch of images of the given amount.\n",
        "        \"\"\"\n",
        "        IMAGE_MAX_VALUE = 255\n",
        "\n",
        "        current_index = 0\n",
        "        while current_index + batch_size <= self.shape[0]:\n",
        "            data_batch = get_batch(\n",
        "                self.data_files[current_index : current_index + batch_size],\n",
        "                self.image_mode,\n",
        "            )\n",
        "\n",
        "            current_index += batch_size\n",
        "\n",
        "            yield data_batch / IMAGE_MAX_VALUE - 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ5vYEzlckX5"
      },
      "source": [
        "This code below will display 9 of our resized images by using the `images_square_grid` function that was defined earlier. This lets us know that the preprocessing worked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUkW_Ylyrkke"
      },
      "outputs": [],
      "source": [
        "# Create a list of the files in our resized images folder\n",
        "resized_data_filenames = [\n",
        "    data_resized_dir + \"/\" + i for i in os.listdir(data_resized_dir)\n",
        "]\n",
        "show_n_images = 9\n",
        "# Get a batch of 9 of the resized images\n",
        "train_images = get_batch(resized_data_filenames[:show_n_images], \"RGB\")\n",
        "# Create a grid from the resized images and then plot them\n",
        "plt.imshow(images_square_grid(train_images, \"RGB\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJUiakoXckX5"
      },
      "source": [
        "## DCGAN\n",
        "\n",
        "### Input\n",
        "\n",
        "Create `placeholder`s with Tensorflow. We need to make special floats used by Tensorflow that will control the behaviour of our models. But because those values haven't been defined yet, the `placeholder`s will act as empty values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVPRWWhIDUdi"
      },
      "outputs": [],
      "source": [
        "def model_inputs(real_dim: int, z_dim: int):\n",
        "    \"\"\"Creates a set of model inputs.\n",
        "\n",
        "    Args:\n",
        "        real_dim (int): _description_\n",
        "        z_dim (int): _description_\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "    \"\"\"\n",
        "    inputs_real = tf.compat.v1.placeholder(\n",
        "        tf.float32, (None, *real_dim), name=\"inputs_real\"\n",
        "    )\n",
        "    inputs_z = tf.compat.v1.placeholder(tf.float32, (None, z_dim), name=\"input_z\")\n",
        "    learning_rate_G = tf.compat.v1.placeholder(tf.float32, name=\"learning_rate_G\")\n",
        "    learning_rate_D = tf.compat.v1.placeholder(tf.float32, name=\"learning_rate_D\")\n",
        "\n",
        "    return inputs_real, inputs_z, learning_rate_G, learning_rate_D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIJCQB02ckX5"
      },
      "source": [
        "## Creating a Generator\n",
        "\n",
        "Tensowflow allows us to group variables together in a `variable_scope`. This means that the variables belonging to the generator will all have `generator` in the name, and likewise, the variables belonging to the discriminator will have `discriminator` in the name.\n",
        "\n",
        "This approach also means that the netowrks can be reused with different inputs.\n",
        "- Generator: The generator will be trained, but we're also going to be sampling from it (retrieving our fake data) during the training.\n",
        "- Discriminator: The discriminator will need to share images between the fake and real input images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OrZ8idXDYfy"
      },
      "outputs": [],
      "source": [
        "def generator(z, output_channel_dim, is_train=True):\n",
        "    \"\"\"Builds the generator network.\n",
        "\n",
        "    Args:\n",
        "        z (_type_): Input tensor for the generator.\n",
        "        output_channel_dim (_type_): Shape of the generator output.\n",
        "        is_train (bool, optional): True if the generator should train, and False to simply sample it.\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "    \"\"\"\n",
        "    with tf.compat.v1.variable_scope(\"generator\", reuse=not is_train):\n",
        "        # First FC layer --> 8x8x1024\n",
        "        fc1 = tf.compat.v1.layers.dense(z, 8 * 8 * 1024)\n",
        "\n",
        "        # Reshape it\n",
        "        fc1 = tf.reshape(fc1, (-1, 8, 8, 1024))\n",
        "\n",
        "        # Leaky ReLU\n",
        "        fc1 = tf.nn.leaky_relu(fc1, alpha=alpha)\n",
        "\n",
        "        # Transposed conv 1 --> BatchNorm --> LeakyReLU\n",
        "        # 8x8x1024 --> 16x16x512\n",
        "        trans_conv1 = tf.compat.v1.layers.conv2d_transpose(\n",
        "            inputs=fc1,\n",
        "            filters=512,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[2, 2],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"trans_conv1\",\n",
        "        )\n",
        "\n",
        "        batch_trans_conv1 = tf.compat.v1.layers.batch_normalization(\n",
        "            inputs=trans_conv1,\n",
        "            training=is_train,\n",
        "            epsilon=1e-5,\n",
        "            name=\"batch_trans_conv1\",\n",
        "        )\n",
        "\n",
        "        trans_conv1_out = tf.nn.leaky_relu(\n",
        "            batch_trans_conv1, alpha=alpha, name=\"trans_conv1_out\"\n",
        "        )\n",
        "\n",
        "        # Transposed conv 2 --> BatchNorm --> LeakyReLU\n",
        "        # 16x16x512 --> 32x32x256\n",
        "        trans_conv2 = tf.compat.v1.layers.conv2d_transpose(\n",
        "            inputs=trans_conv1_out,\n",
        "            filters=256,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[2, 2],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"trans_conv2\",\n",
        "        )\n",
        "\n",
        "        batch_trans_conv2 = tf.compat.v1.layers.batch_normalization(\n",
        "            inputs=trans_conv2,\n",
        "            training=is_train,\n",
        "            epsilon=1e-5,\n",
        "            name=\"batch_trans_conv2\",\n",
        "        )\n",
        "\n",
        "        trans_conv2_out = tf.nn.leaky_relu(\n",
        "            batch_trans_conv2, alpha=alpha, name=\"trans_conv2_out\"\n",
        "        )\n",
        "\n",
        "        # Transposed conv 3 --> BatchNorm --> LeakyReLU\n",
        "        # 32x32x256 --> 64x64x128\n",
        "        trans_conv3 = tf.compat.v1.layers.conv2d_transpose(\n",
        "            inputs=trans_conv2_out,\n",
        "            filters=128,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[2, 2],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"trans_conv3\",\n",
        "        )\n",
        "\n",
        "        batch_trans_conv3 = tf.compat.v1.layers.batch_normalization(\n",
        "            inputs=trans_conv3,\n",
        "            training=is_train,\n",
        "            epsilon=1e-5,\n",
        "            name=\"batch_trans_conv3\",\n",
        "        )\n",
        "\n",
        "        trans_conv3_out = tf.nn.leaky_relu(\n",
        "            batch_trans_conv3, alpha=alpha, name=\"trans_conv3_out\"\n",
        "        )\n",
        "\n",
        "        # Transposed conv 4 --> BatchNorm --> LeakyReLU\n",
        "        # 64x64x128 --> 128x128x64\n",
        "        trans_conv4 = tf.compat.v1.layers.conv2d_transpose(\n",
        "            inputs=trans_conv3_out,\n",
        "            filters=64,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[2, 2],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"trans_conv4\",\n",
        "        )\n",
        "\n",
        "        batch_trans_conv4 = tf.compat.v1.layers.batch_normalization(\n",
        "            inputs=trans_conv4,\n",
        "            training=is_train,\n",
        "            epsilon=1e-5,\n",
        "            name=\"batch_trans_conv4\",\n",
        "        )\n",
        "\n",
        "        trans_conv4_out = tf.nn.leaky_relu(\n",
        "            batch_trans_conv4, alpha=alpha, name=\"trans_conv4_out\"\n",
        "        )\n",
        "\n",
        "        # Transposed conv 5 --> tanh\n",
        "        # 128x128x64 --> 128x128x3\n",
        "        logits = tf.compat.v1.layers.conv2d_transpose(\n",
        "            inputs=trans_conv4_out,\n",
        "            filters=3,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[1, 1],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"logits\",\n",
        "        )\n",
        "\n",
        "        out = tf.tanh(logits, name=\"out\")\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTJa7gsickX6"
      },
      "source": [
        "## Creating a Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfguoTo4DdEr"
      },
      "outputs": [],
      "source": [
        "def discriminator(x, is_reuse=False, alpha=0.2):\n",
        "    \"\"\"Build the discriminator network.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    x : Input tensor for the discriminator\n",
        "    n_units: Number of units in hidden layer\n",
        "    reuse : Reuse the variables with tf.variable_scope\n",
        "    alpha : leak parameter for leaky ReLU\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    out, logits:\n",
        "    \"\"\"\n",
        "    with tf.compat.v1.variable_scope(\"discriminator\", reuse=is_reuse):\n",
        "        # Input layer 128*128*3 --> 64x64x64\n",
        "        # Conv --> BatchNorm --> LeakyReLU\n",
        "        conv1 = tf.compat.v1.layers.conv2d(\n",
        "            inputs=x,\n",
        "            filters=64,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[2, 2],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"conv1\",\n",
        "        )\n",
        "\n",
        "        batch_norm1 = tf.compat.v1.layers.batch_normalization(\n",
        "            conv1, training=True, epsilon=1e-5, name=\"batch_norm1\"\n",
        "        )\n",
        "\n",
        "        conv1_out = tf.nn.leaky_relu(batch_norm1, alpha=alpha, name=\"conv1_out\")\n",
        "\n",
        "        # 64x64x64--> 32x32x128\n",
        "        # Conv --> BatchNorm --> LeakyReLU\n",
        "        conv2 = tf.compat.v1.layers.conv2d(\n",
        "            inputs=conv1_out,\n",
        "            filters=128,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[2, 2],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"conv2\",\n",
        "        )\n",
        "\n",
        "        batch_norm2 = tf.compat.v1.layers.batch_normalization(\n",
        "            conv2, training=True, epsilon=1e-5, name=\"batch_norm2\"\n",
        "        )\n",
        "\n",
        "        conv2_out = tf.nn.leaky_relu(batch_norm2, alpha=alpha, name=\"conv2_out\")\n",
        "\n",
        "        # 32x32x128 --> 16x16x256\n",
        "        # Conv --> BatchNorm --> LeakyReLU\n",
        "        conv3 = tf.compat.v1.layers.conv2d(\n",
        "            inputs=conv2_out,\n",
        "            filters=256,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[2, 2],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"conv3\",\n",
        "        )\n",
        "\n",
        "        batch_norm3 = tf.compat.v1.layers.batch_normalization(\n",
        "            conv3, training=True, epsilon=1e-5, name=\"batch_norm3\"\n",
        "        )\n",
        "\n",
        "        conv3_out = tf.nn.leaky_relu(batch_norm3, alpha=alpha, name=\"conv3_out\")\n",
        "\n",
        "        # 16x16x256 --> 16x16x512\n",
        "        # Conv --> BatchNorm --> LeakyReLU\n",
        "        conv4 = tf.compat.v1.layers.conv2d(\n",
        "            inputs=conv3_out,\n",
        "            filters=512,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[1, 1],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"conv4\",\n",
        "        )\n",
        "\n",
        "        batch_norm4 = tf.compat.v1.layers.batch_normalization(\n",
        "            conv4, training=True, epsilon=1e-5, name=\"batch_norm4\"\n",
        "        )\n",
        "\n",
        "        conv4_out = tf.nn.leaky_relu(batch_norm4, alpha=alpha, name=\"conv4_out\")\n",
        "\n",
        "        # 16x16x512 --> 8x8x1024\n",
        "        # Conv --> BatchNorm --> LeakyReLU\n",
        "        conv5 = tf.compat.v1.layers.conv2d(\n",
        "            inputs=conv4_out,\n",
        "            filters=1024,\n",
        "            kernel_size=[5, 5],\n",
        "            strides=[2, 2],\n",
        "            padding=\"SAME\",\n",
        "            kernel_initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02),\n",
        "            name=\"conv5\",\n",
        "        )\n",
        "\n",
        "        batch_norm5 = tf.compat.v1.layers.batch_normalization(\n",
        "            conv5, training=True, epsilon=1e-5, name=\"batch_norm5\"\n",
        "        )\n",
        "\n",
        "        conv5_out = tf.nn.leaky_relu(batch_norm5, alpha=alpha, name=\"conv5_out\")\n",
        "\n",
        "        # Flatten it\n",
        "        flatten = tf.reshape(conv5_out, (-1, 8 * 8 * 1024))\n",
        "\n",
        "        # Logits\n",
        "        logits = tf.compat.v1.layers.dense(inputs=flatten, units=1, activation=None)\n",
        "\n",
        "        out = tf.sigmoid(logits)\n",
        "\n",
        "        return out, logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5geGuwZpckX6"
      },
      "source": [
        "## Compute the Loss\n",
        "\n",
        "The loss tells us how well the GAN is doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6M04hCmDjdq"
      },
      "outputs": [],
      "source": [
        "def model_loss(input_real, input_z, output_channel_dim, alpha):\n",
        "    \"\"\"Find the loss for the generator and the discriminator.\n",
        "\n",
        "    Args:\n",
        "        input_real (np.ndarray): Images from the real dataset.\n",
        "        input_z (_type_): Z input.\n",
        "        output_channel_dim (int): The number of channels in the output image.\n",
        "        alpha (float): _description_\n",
        "\n",
        "    Returns:\n",
        "        tuple: The discriminator loss and generator loss.\n",
        "    \"\"\"\n",
        "    # Generator network here\n",
        "    g_model = generator(input_z, output_channel_dim)\n",
        "    # g_model is the generator output\n",
        "\n",
        "    # Discriminator network here\n",
        "    d_model_real, d_logits_real = discriminator(input_real, alpha=alpha)\n",
        "    d_model_fake, d_logits_fake = discriminator(g_model, is_reuse=True, alpha=alpha)\n",
        "\n",
        "    # Calculate losses\n",
        "    d_loss_real = tf.reduce_mean(\n",
        "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=d_logits_real, labels=tf.ones_like(d_model_real)\n",
        "        )\n",
        "    )\n",
        "    d_loss_fake = tf.reduce_mean(\n",
        "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=d_logits_fake, labels=tf.zeros_like(d_model_fake)\n",
        "        )\n",
        "    )\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "    g_loss = tf.reduce_mean(\n",
        "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=d_logits_fake, labels=tf.ones_like(d_model_fake)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return d_loss, g_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEfEYlYCDvEL"
      },
      "outputs": [],
      "source": [
        "def model_optimizers(d_loss, g_loss, lr_D, lr_G, beta1):\n",
        "    \"\"\"\n",
        "    Get optimization operations\n",
        "    :param d_loss: Discriminator loss Tensor\n",
        "    :param g_loss: Generator loss Tensor\n",
        "    :param learning_rate: Learning Rate Placeholder\n",
        "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
        "    :return: A tuple of (discriminator training operation, generator training operation)\n",
        "    \"\"\"\n",
        "    # Get the trainable_variables, split into G and D parts\n",
        "    t_vars = tf.compat.v1.trainable_variables()\n",
        "    g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
        "    d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
        "\n",
        "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
        "\n",
        "    # Generator update\n",
        "    gen_updates = [op for op in update_ops if op.name.startswith(\"generator\")]\n",
        "\n",
        "    # Optimizers\n",
        "    with tf.control_dependencies(gen_updates):\n",
        "        d_train_opt = tf.compat.v1.train.AdamOptimizer(\n",
        "            learning_rate=lr_D, beta1=beta1\n",
        "        ).minimize(d_loss, var_list=d_vars)\n",
        "        g_train_opt = tf.compat.v1.train.AdamOptimizer(\n",
        "            learning_rate=lr_G, beta1=beta1\n",
        "        ).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "    return d_train_opt, g_train_opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjMWpEbgckX7"
      },
      "source": [
        "This will show an image of our fake data while the GAN is running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QblwpY0DDx-F"
      },
      "outputs": [],
      "source": [
        "def show_generator_output(\n",
        "    sess, n_images, input_z, out_channel_dim, image_mode, image_path, save, show\n",
        "):\n",
        "    \"\"\"\n",
        "    Show example output for the generator\n",
        "    :param sess: TensorFlow session\n",
        "    :param n_images: Number of Images to display\n",
        "    :param input_z: Input Z Tensor\n",
        "    :param out_channel_dim: The number of channels in the output image\n",
        "    :param image_mode: The mode to use for images (\"RGB\" or \"L\")\n",
        "    :param image_path: Path to save the image\n",
        "    \"\"\"\n",
        "    cmap = None if image_mode == \"RGB\" else \"gray\"\n",
        "    z_dim = input_z.get_shape().as_list()[-1]\n",
        "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
        "\n",
        "    samples = sess.run(\n",
        "        generator(input_z, out_channel_dim, False), feed_dict={input_z: example_z}\n",
        "    )\n",
        "\n",
        "    images_grid = images_square_grid(samples, image_mode)\n",
        "\n",
        "    if save:\n",
        "        # Save image\n",
        "        images_grid.save(image_path, \"JPEG\")\n",
        "\n",
        "    if show:\n",
        "        display.clear_output(wait=True)\n",
        "        plt.imshow(images_grid, cmap=cmap)\n",
        "        display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYgF4FEvD11n"
      },
      "outputs": [],
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1A9dcffckX8"
      },
      "source": [
        "## Define the Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPQLMoXoEHHI"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    epoch_count,\n",
        "    batch_size,\n",
        "    z_dim,\n",
        "    learning_rate_D,\n",
        "    learning_rate_G,\n",
        "    beta1,\n",
        "    get_batches,\n",
        "    data_shape,\n",
        "    data_image_mode,\n",
        "    alpha,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train the GAN\n",
        "    :param epoch_count: Number of epochs\n",
        "    :param batch_size: Batch Size\n",
        "    :param z_dim: Z dimension\n",
        "    :param learning_rate: Learning Rate\n",
        "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
        "    :param get_batches: Function to get batches\n",
        "    :param data_shape: Shape of the data\n",
        "    :param data_image_mode: The image mode to use for images (\"RGB\" or \"L\")\n",
        "    \"\"\"\n",
        "    # Create our input placeholders\n",
        "    input_images, input_z, lr_G, lr_D = model_inputs(data_shape[1:], z_dim)\n",
        "\n",
        "    # Losses\n",
        "    d_loss, g_loss = model_loss(input_images, input_z, data_shape[3], alpha)\n",
        "\n",
        "    # Optimizers\n",
        "    d_opt, g_opt = model_optimizers(d_loss, g_loss, lr_D, lr_G, beta1)\n",
        "\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "\n",
        "    with tf.compat.v1.Session(config=config) as sess:\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "        # Saver\n",
        "        saver = tf.compat.v1.train.Saver()\n",
        "\n",
        "        num_epoch = 0\n",
        "\n",
        "        if not os.path.isdir(image_folder):\n",
        "            os.mkdir(image_folder)\n",
        "\n",
        "        if not os.path.isdir(models_folder):\n",
        "            os.mkdir(models_folder)\n",
        "        model_save_path = os.path.join(models_folder, \"model.cpkt\")\n",
        "\n",
        "        if from_checkpoint:\n",
        "            saver.restore(sess, model_save_path)\n",
        "            image_path = \"new_train/new_gen_image.jpg\"\n",
        "            show_generator_output(\n",
        "                sess,\n",
        "                1,\n",
        "                input_z,\n",
        "                data_shape[3],\n",
        "                data_image_mode,\n",
        "                image_path,\n",
        "                False,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        for epoch_i in range(epoch_count):\n",
        "            num_epoch += 1\n",
        "            if num_epoch % 5 == 0:\n",
        "                saver.save(sess, model_save_path)\n",
        "                print(\"Model saved\")\n",
        "\n",
        "            # saves model every 50 epochs\n",
        "            if epoch_i > 50 and epoch_i % 50 == 0:\n",
        "                saver.save(\n",
        "                    sess, model_save_path, global_step=epoch_i, write_meta_graph=False\n",
        "                )\n",
        "            for batch_images in get_batches(batch_size):\n",
        "                # Random noise\n",
        "                batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
        "                # Run optimizers\n",
        "                _ = sess.run(\n",
        "                    d_opt,\n",
        "                    feed_dict={\n",
        "                        input_images: batch_images,\n",
        "                        input_z: batch_z,\n",
        "                        lr_D: learning_rate_D,\n",
        "                    },\n",
        "                )\n",
        "                _ = sess.run(\n",
        "                    g_opt,\n",
        "                    feed_dict={\n",
        "                        input_images: batch_images,\n",
        "                        input_z: batch_z,\n",
        "                        lr_G: learning_rate_G,\n",
        "                    },\n",
        "                )\n",
        "\n",
        "            # will calculate losses and generate an image for each epoch\n",
        "\n",
        "            train_loss_d = d_loss.eval({input_z: batch_z, input_images: batch_images})\n",
        "            train_loss_g = g_loss.eval({input_z: batch_z})\n",
        "            g_losses.append(train_loss_g)\n",
        "            d_losses.append(train_loss_d)\n",
        "            # Save it\n",
        "            image_name = str(epoch_i) + \".jpg\"\n",
        "            image_path = os.path.join(image_folder, image_name)\n",
        "\n",
        "            plt.title(f\"Epoch {epoch_i + 1}\")\n",
        "            show_generator_output(\n",
        "                sess, 9, input_z, data_shape[3], data_image_mode, image_path, True, True\n",
        "            )\n",
        "            print(\n",
        "                \"Epoch {}/{} |\".format(epoch_i + 1, epoch_count),\n",
        "                \"Discriminator Loss: {:.4f} |\".format(train_loss_d),\n",
        "                \"Generator Loss: {:.4f}\".format(train_loss_g),\n",
        "            )\n",
        "\n",
        "    return d_losses, g_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMSioXrGckX8"
      },
      "source": [
        "## Set the Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LQBDqPzEkH5"
      },
      "outputs": [],
      "source": [
        "# Size input image for discriminator\n",
        "real_size = (128, 128, 3)\n",
        "\n",
        "# Size of latent vector to generator\n",
        "z_dim = 100\n",
        "learning_rate_D = 0.000005  # Thanks to Alexia Jolicoeur Martineau https://ajolicoeur.wordpress.com/cats/\n",
        "learning_rate_G = 0.00002  # Thanks to Alexia Jolicoeur Martineau https://ajolicoeur.wordpress.com/cats/\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "alpha = 0.2\n",
        "beta1 = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2gbQewtEoWP"
      },
      "outputs": [],
      "source": [
        "# Load the data and train the network here\n",
        "dataset = Dataset(resized_data_filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMkIdSOeEs3B"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImbXZbyPckX9"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtqOrcWuEwC6"
      },
      "outputs": [],
      "source": [
        "with tf.Graph().as_default():\n",
        "    d_losses, g_losses = train(\n",
        "        epochs,\n",
        "        batch_size,\n",
        "        z_dim,\n",
        "        learning_rate_D,\n",
        "        learning_rate_G,\n",
        "        beta1,\n",
        "        dataset.get_batches,\n",
        "        dataset.shape,\n",
        "        dataset.image_mode,\n",
        "        alpha,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwuqbLbCckX9"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "d_losses = np.array(d_losses)\n",
        "g_losses = np.array(g_losses)\n",
        "plt.plot(d_losses, label=\"Discriminator\", alpha=0.5)\n",
        "plt.plot(g_losses, label=\"Generator\", alpha=0.5)\n",
        "plt.title(\"Training Losses\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpgKHUxcckX-"
      },
      "source": [
        "## Improving the Generated Images\n",
        "\n",
        "- Give it a larger dataset (>10K images)\n",
        "- Run for a larger number of epochs\n",
        "\n",
        "## Learning More About GANs\n",
        "\n",
        "- Google GANs Course: https://developers.google.com/machine-learning/gan\n",
        "- Neural Networks video series: https://youtu.be/aircAruvnKk?si=TA18yaGIBzyd9cdO\n",
        "\n",
        "## Interesting ML / GANs Tools\n",
        "\n",
        "- [Machine Learning for Art](https://ml4a.net/)\n",
        "- [Text to Image](https://colab.research.google.com/drive/1L14q4To5rMK8q2E6whOibQBnPnVbRJ_7?usp=sharing) Notebook. Also a [blog post](https://amyelizabethsmith01.medium.com/gans-sanrio-ganrio-21e263666929) about the notebook.\n",
        "- Awesome Applications of GANs: https://github.com/nashory/gans-awesome-applications\n",
        "\n",
        "## Feedback\n",
        "\n",
        "Please fill in the feedback form: https://moodle.arts.ac.uk/mod/feedback/view.php?id=1365755\n",
        "\n",
        "## Attendance\n",
        "\n",
        "Please give me your names so I can keep track of attendance!\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}